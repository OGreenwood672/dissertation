training:
  training_timesteps: 7500
  simulation_timesteps: 300
  timestep: 0
  buffer_size: 128
  worlds_parallised: 32
  seed: 21
  periodic_save_interval: 100

ppo_hyperparameters:
  ppo_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_coef: 0.2
  vf_coef: 0.5
  ent_coef: 0.03
  actor_learning_rate: 0.0001
  critic_learning_rate: 0.0001

architecture:
  lstm_hidden_size: 64
  feature_dim: 256

experiment:
  communication_type: continuous
  aim_seed: 28
  vocab_size: 64
  communication_size: 8
  num_comms: 4
